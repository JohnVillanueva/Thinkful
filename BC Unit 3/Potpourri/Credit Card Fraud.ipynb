{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "transacs = pd.read_csv('../../__DATA__/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transacs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10724ee50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrmat = transacs.corr()\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(corrmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Unknown property style",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-85db92c1bf53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfrauds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransacs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransacs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrauds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfrauds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m                                   \"with non-matching shapes is deprecated.\")\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mncx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mncy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_makeline\u001b[0;34m(self, x, y, kw, kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mdefault_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getdefaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setdefaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# update kwargs before updating data to give the caller a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# chance to init axes (and hence unit support)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickradius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickradius\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mind_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, props)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meventson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_update_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meventson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_update_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_update_property\u001b[0;34m(self, k, v)\u001b[0m\n\u001b[1;32m    910\u001b[0m                 \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'set_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown property %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Unknown property style"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "frauds = transacs.loc[transacs['Class']==1]\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Strategy:\n",
    "Keep many models in mind: SVC, Decision Trees, Regressions, Boosting Methods. The modeling methods that probability would not work are the Naive Bayes classifier and KNN classifiers, because the data here is very complex and interconnected - these said models rely ignore dependence between features and rely too heavily on similarity.\n",
    "\n",
    "SVC and Lasso/Ridge Logistic Regression are great starting points, then bagging and boosting methods next. Each modeling method will be iterated with over/undersampling of the minority or majority to refine the sensitvity (detection of False Negative).\n",
    "\n",
    "We also need to make sure to get rid of the outliers if any. PCA, while sensitive to outliers, does not necessarily rid of them entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float64Index([   383.0,    514.0,    534.0,    541.0,    575.0,    936.0,\n",
       "                1059.0,   1072.0,   1170.0,   1526.0,\n",
       "              ...\n",
       "              281731.0, 281963.0, 282500.0, 282596.0, 282904.0, 283719.0,\n",
       "              283782.0, 283949.0, 284085.0, 284770.0],\n",
       "             dtype='float64', length=1825)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transacs['Amount'].index.where(transacs.Amount == 0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      -0.035568\n",
       "V1        -3.280667\n",
       "V2        -4.624866\n",
       "V3        -2.240155\n",
       "V4         0.676292\n",
       "V5        -2.425901\n",
       "V6         1.826581\n",
       "V7         2.553907\n",
       "V8        -8.521944\n",
       "V9         0.554680\n",
       "V10        1.187141\n",
       "V11        0.356506\n",
       "V12       -2.278401\n",
       "V13        0.065233\n",
       "V14       -1.995176\n",
       "V15       -0.308423\n",
       "V16       -1.100966\n",
       "V17       -3.844914\n",
       "V18       -0.259880\n",
       "V19        0.109192\n",
       "V20       -2.037155\n",
       "V21        3.592991\n",
       "V22       -0.213258\n",
       "V23       -5.875140\n",
       "V24       -0.552499\n",
       "V25       -0.415793\n",
       "V26        0.576693\n",
       "V27       -1.170209\n",
       "V28       11.192091\n",
       "Amount    16.977724\n",
       "Class     23.997579\n",
       "dtype: float64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DF1, where\n",
    "index = transacs['Amount'].index.where(transacs.Amount > 0).dropna()\n",
    "df1 = transacs.iloc[index,:]\n",
    "#df1.skew() <= -2\n",
    "transacs.skew() #.columns.where(df1.skew() <= -2).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  nan,  'V1',  'V2',  'V3',   nan,  'V5',   nan,   nan,  'V8',   nan,\n",
       "         nan,   nan, 'V12',   nan,   nan,   nan,   nan, 'V17',   nan,   nan,\n",
       "       'V20',   nan,   nan, 'V23',   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transacs.columns.where(transacs.skew() <= -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_root = transacs.columns.where(transacs.skew() <= -2).dropna()\n",
    "cols_log = transacs.columns.where(transacs.skew() >= 2).dropna()\n",
    "cols_log = cols_log.drop('Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in transacs.columns.drop(['Time','Class']):\n",
    "    if min(transacs[i]) <= 0:\n",
    "        df1[i] = transacs[i] + abs(min(transacs[i])) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols_root:\n",
    "    df1[i] = df1[i]**(1/2)\n",
    "for i in cols_log:\n",
    "    df1[i] = np.log(df1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.486501</td>\n",
       "      <td>8.581547</td>\n",
       "      <td>7.201523</td>\n",
       "      <td>8.061326</td>\n",
       "      <td>10.696027</td>\n",
       "      <td>27.622894</td>\n",
       "      <td>3.802138</td>\n",
       "      <td>8.620639</td>\n",
       "      <td>14.797853</td>\n",
       "      <td>...</td>\n",
       "      <td>3.578285</td>\n",
       "      <td>12.210981</td>\n",
       "      <td>6.759975</td>\n",
       "      <td>3.903555</td>\n",
       "      <td>11.423936</td>\n",
       "      <td>3.415436</td>\n",
       "      <td>23.699238</td>\n",
       "      <td>2.797832</td>\n",
       "      <td>5.014760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.655022</td>\n",
       "      <td>8.601272</td>\n",
       "      <td>7.035060</td>\n",
       "      <td>7.131325</td>\n",
       "      <td>10.714631</td>\n",
       "      <td>27.078145</td>\n",
       "      <td>3.795005</td>\n",
       "      <td>8.619850</td>\n",
       "      <td>14.178641</td>\n",
       "      <td>...</td>\n",
       "      <td>3.572475</td>\n",
       "      <td>11.294472</td>\n",
       "      <td>6.775620</td>\n",
       "      <td>3.496780</td>\n",
       "      <td>11.462567</td>\n",
       "      <td>3.730445</td>\n",
       "      <td>23.556696</td>\n",
       "      <td>2.800010</td>\n",
       "      <td>1.305626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.486598</td>\n",
       "      <td>8.507383</td>\n",
       "      <td>7.148342</td>\n",
       "      <td>7.062951</td>\n",
       "      <td>10.688316</td>\n",
       "      <td>28.961005</td>\n",
       "      <td>3.814382</td>\n",
       "      <td>8.629275</td>\n",
       "      <td>12.919412</td>\n",
       "      <td>...</td>\n",
       "      <td>3.585694</td>\n",
       "      <td>12.704823</td>\n",
       "      <td>6.834994</td>\n",
       "      <td>3.147346</td>\n",
       "      <td>10.967755</td>\n",
       "      <td>3.465454</td>\n",
       "      <td>23.510327</td>\n",
       "      <td>2.795471</td>\n",
       "      <td>5.939276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.512738</td>\n",
       "      <td>8.574993</td>\n",
       "      <td>7.149726</td>\n",
       "      <td>5.819880</td>\n",
       "      <td>10.711349</td>\n",
       "      <td>28.407709</td>\n",
       "      <td>3.802093</td>\n",
       "      <td>8.636791</td>\n",
       "      <td>13.047042</td>\n",
       "      <td>...</td>\n",
       "      <td>3.575769</td>\n",
       "      <td>11.938417</td>\n",
       "      <td>6.754067</td>\n",
       "      <td>2.661052</td>\n",
       "      <td>11.942773</td>\n",
       "      <td>3.382622</td>\n",
       "      <td>23.628402</td>\n",
       "      <td>2.802848</td>\n",
       "      <td>4.824306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.499952</td>\n",
       "      <td>8.636751</td>\n",
       "      <td>7.132623</td>\n",
       "      <td>7.086205</td>\n",
       "      <td>10.692807</td>\n",
       "      <td>27.256427</td>\n",
       "      <td>3.809994</td>\n",
       "      <td>8.599197</td>\n",
       "      <td>15.251806</td>\n",
       "      <td>...</td>\n",
       "      <td>3.578533</td>\n",
       "      <td>12.731422</td>\n",
       "      <td>6.757979</td>\n",
       "      <td>3.977894</td>\n",
       "      <td>11.089387</td>\n",
       "      <td>4.106843</td>\n",
       "      <td>23.785102</td>\n",
       "      <td>2.812124</td>\n",
       "      <td>4.262539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4         V5         V6  \\\n",
       "0   0.0  7.486501  8.581547  7.201523  8.061326  10.696027  27.622894   \n",
       "1   0.0  7.655022  8.601272  7.035060  7.131325  10.714631  27.078145   \n",
       "2   1.0  7.486598  8.507383  7.148342  7.062951  10.688316  28.961005   \n",
       "3   1.0  7.512738  8.574993  7.149726  5.819880  10.711349  28.407709   \n",
       "4   2.0  7.499952  8.636751  7.132623  7.086205  10.692807  27.256427   \n",
       "\n",
       "         V7        V8         V9  ...       V21        V22       V23  \\\n",
       "0  3.802138  8.620639  14.797853  ...  3.578285  12.210981  6.759975   \n",
       "1  3.795005  8.619850  14.178641  ...  3.572475  11.294472  6.775620   \n",
       "2  3.814382  8.629275  12.919412  ...  3.585694  12.704823  6.834994   \n",
       "3  3.802093  8.636791  13.047042  ...  3.575769  11.938417  6.754067   \n",
       "4  3.809994  8.599197  15.251806  ...  3.578533  12.731422  6.757979   \n",
       "\n",
       "        V24        V25       V26        V27       V28    Amount  Class  \n",
       "0  3.903555  11.423936  3.415436  23.699238  2.797832  5.014760      0  \n",
       "1  3.496780  11.462567  3.730445  23.556696  2.800010  1.305626      0  \n",
       "2  3.147346  10.967755  3.465454  23.510327  2.795471  5.939276      0  \n",
       "3  2.661052  11.942773  3.382622  23.628402  2.802848  4.824306      0  \n",
       "4  3.977894  11.089387  4.106843  23.785102  2.812124  4.262539      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      -0.035448\n",
       "V1        -1.392947\n",
       "V2         0.942889\n",
       "V3        -0.091308\n",
       "V4         0.662613\n",
       "V5         1.011695\n",
       "V6         1.848706\n",
       "V7        -1.219334\n",
       "V8         1.477333\n",
       "V9         0.566120\n",
       "V10        1.257844\n",
       "V11        0.349984\n",
       "V12        0.019785\n",
       "V13        0.064628\n",
       "V14       -1.932348\n",
       "V15       -0.308001\n",
       "V16       -1.090530\n",
       "V17        0.714944\n",
       "V18       -0.257482\n",
       "V19        0.113700\n",
       "V20        2.074979\n",
       "V21       -0.811227\n",
       "V22       -0.218699\n",
       "V23        2.730036\n",
       "V24       -0.551418\n",
       "V25       -0.416507\n",
       "V26        0.572951\n",
       "V27       -1.195767\n",
       "V28       -0.650334\n",
       "Amount    -0.230509\n",
       "Class     24.608363\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1825"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transacs['Amount'].where(transacs.Amount == 0).count()\n",
    "#plt.hist(transacs['Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resampling to Control Number of non-fraud transaction in training set\n",
    "index_pos = df1['Class'].index.where(df1.Class == 1).dropna().tolist()\n",
    "index_neg = df1['Class'].index.where(df1.Class == 0).dropna().tolist()\n",
    "index_pos = [ int(x) for x in index_pos ]\n",
    "index_neg = [ int(x) for x in index_neg ]\n",
    "random.sample(index_neg, len(index_pos))\n",
    "index_neg = random.sample(index_neg, int(len(index_pos)))\n",
    "index_pos.extend(index_neg)\n",
    "index_pos.sort()\n",
    "modeldf = df1.loc[index_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4787234, 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "       0.5      , 0.5      , 0.5      , 0.5      ])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = modeldf.iloc[:,:30]\n",
    "Y = modeldf['Class']\n",
    "\n",
    "clf = LogisticRegression(solver='sag', penalty='none')\n",
    "clf.fit(X,Y)\n",
    "cross_val_score(clf, X, Y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration: Logistic Regression, Only 'Amount' Transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new population df with untransformed data\n",
    "df2 = transacs\n",
    "df2['Amount'] = df2['Amount'] + abs(min(transacs['Amount'])) + 1\n",
    "df2['Amount'] = np.log(df2['Amount'])\n",
    "\n",
    "#Resampling to Control Number of non-fraud transaction in training set\n",
    "index_pos = df2['Class'].index.where(df2.Class == 1).dropna().tolist()\n",
    "index_neg = df2['Class'].index.where(df2.Class == 0).dropna().tolist()\n",
    "index_pos = [ int(x) for x in index_pos ]\n",
    "index_neg = [ int(x) for x in index_neg ]\n",
    "random.sample(index_neg, len(index_pos))\n",
    "index_neg = random.sample(index_neg, int(len(index_neg)*0.1))\n",
    "index_pos.extend(index_neg)\n",
    "index_pos.sort()\n",
    "modeldf = df2.loc[index_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = modeldf.iloc[:,:30]\n",
    "Y = modeldf['Class']\n",
    "\n",
    "clf = LogisticRegression(solver='sag', penalty='none')\n",
    "clf.fit(X,Y)\n",
    "cross_val_score(clf, X, Y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration: Random Forest Classifier, Only 'Amount' Transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97      , 0.96      , 1.        , 0.87755102, 0.8877551 ,\n",
       "       0.92857143, 0.95918367, 0.91836735, 0.93877551, 0.89795918])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = modeldf.iloc[:,:30]\n",
    "Y = modeldf['Class']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 500, criterion='entropy',\n",
    "                             max_depth = 5)\n",
    "clf.fit(X,Y)\n",
    "cross_val_score(clf, X, Y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9862784271454003\n",
      "3908 total misclassified out of 284807.\n",
      "\n",
      "Type 2 Error / Unnoticed Fraud: 0.08943089430894309\n",
      "\n",
      "Type 1 Error / Flagged Non-Fraud: 0.01359055976645622\n"
     ]
    }
   ],
   "source": [
    "Xtest = df2.iloc[:,:30]\n",
    "preds = clf.predict(Xtest)\n",
    "pred_counts = (preds == df2['Class']).value_counts()\n",
    "print('Overall Accuracy: {}'.format(pred_counts[1]/pred_counts.sum()))\n",
    "print('{} total misclassified out of {}.'.format(pred_counts[0],pred_counts.sum()))\n",
    "conmax = confusion_matrix(df2['Class'],preds)\n",
    "print('\\nType 2 Error / Unnoticed Fraud: {}'.format(conmax[1,0]/conmax[1].sum()))\n",
    "print('\\nType 1 Error / Flagged Non-Fraud: {}'.format(conmax[0,1]/conmax[0].sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration: Gradient Boosting Classifier, 'Amount' Transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04803041, 0.9972347 , 0.99896266, 0.9944675 , 0.99412172,\n",
       "       0.97233748, 0.99515906, 0.99377593, 0.99585062, 0.99343015])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = modeldf.iloc[:,:30]\n",
    "Y = modeldf['Class']\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators = 200, criterion='friedman_mse',\n",
    "                             max_depth = 3)\n",
    "clf.fit(X,Y)\n",
    "cross_val_score(clf, X, Y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9980337561927902\n",
      "560 total misclassified out of 284807.\n",
      "\n",
      "Type 2 Error / Unnoticed Fraud: 0.008130081300813009\n",
      "\n",
      "Type 1 Error / Flagged Non-Fraud: 0.001955577440514922\n"
     ]
    }
   ],
   "source": [
    "Xtest = df2.iloc[:,:30]\n",
    "preds = clf.predict(Xtest)\n",
    "pred_counts = (preds == df2['Class']).value_counts()\n",
    "print('Overall Accuracy: {}'.format(pred_counts[1]/pred_counts.sum()))\n",
    "print('{} total misclassified out of {}.'.format(pred_counts[0],pred_counts.sum()))\n",
    "conmax = confusion_matrix(df2['Class'],preds)\n",
    "print('\\nType 2 Error / Unnoticed Fraud: {}'.format(conmax[1,0]/conmax[1].sum()))\n",
    "print('\\nType 1 Error / Flagged Non-Fraud: {}'.format(conmax[0,1]/conmax[0].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An iteration using the Gradient Boosting Classifier with an undersampling of negative cases equal to the total fraud cases gave 0% Type 2 error rate, but a ~3% Type 1 Error Rate. The above iteration uses an undersampling of 10% of the total non-fraud cases.\n",
    "\n",
    "It's clear that gradient boosting provides the best accuracy of any of the models.\n",
    "\n",
    "The next iteration will involve experiment with oversampling of the Fraud cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration: GBC w/ oversampling and undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 31)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating new population df with untransformed data\n",
    "df3 = transacs\n",
    "df3['Amount'] = df3['Amount'] + abs(min(transacs['Amount'])) + 1\n",
    "df3['Amount'] = np.log(df3['Amount'])\n",
    "\n",
    "#Resampling to Control Number of non-fraud transaction in training set\n",
    "samples = 3000\n",
    "frauds = df3[df3['Class']==1]\n",
    "posvals = resample(frauds, replace=True, n_samples=samples)\n",
    "nonfrauds = df3[df3['Class']==0]\n",
    "negvals = resample(nonfrauds, replace=True, n_samples=samples)\n",
    "modeldf = pd.concat([posvals, negvals])\n",
    "modeldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99666667, 0.99833333, 0.99666667, 0.99833333, 0.99666667,\n",
       "       1.        , 1.        , 1.        , 0.995     , 0.99666667])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9961763580249081\n",
      "1089 total misclassified out of 284807.\n",
      "\n",
      "Type 2 Error / Unnoticed Fraud: 0.0\n",
      "\n",
      "Type 1 Error / Flagged Non-Fraud: 0.003830258691943795\n"
     ]
    }
   ],
   "source": [
    "X = modeldf.iloc[:,:30]\n",
    "Y = modeldf['Class']\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators = 300, criterion='friedman_mse',\n",
    "                             max_depth = 6)\n",
    "clf.fit(X,Y)\n",
    "display(cross_val_score(clf, X, Y, cv=10))\n",
    "\n",
    "Xtest = df3.iloc[:,:30]\n",
    "preds = clf.predict(Xtest)\n",
    "pred_counts = (preds == df3['Class']).value_counts()\n",
    "print('Overall Accuracy: {}'.format(pred_counts[1]/pred_counts.sum()))\n",
    "print('{} total misclassified out of {}.'.format(pred_counts[0],pred_counts.sum()))\n",
    "conmax = confusion_matrix(df2['Class'],preds)\n",
    "print('\\nType 2 Error / Unnoticed Fraud: {}'.format(conmax[1,0]/conmax[1].sum()))\n",
    "print('\\nType 1 Error / Flagged Non-Fraud: {}'.format(conmax[0,1]/conmax[0].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of estimators beyond 300 and max depth past 5 either marginally increased or made no difference to the Error Rates and Accuracy Scores. The above model seems to be the best model achievable. And while there are still a substantial number of flagged non-fraud cases, these errors are much less consequential than misclassifying a fraud case, the errors of which are reduced to zero on the this model when retested on the entire dataset of transactions. This is a very successful model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
